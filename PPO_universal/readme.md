Updated solution supporting four different Policies:
- Discrete
- Gaussian Continous
- Beta Continous
- Discrete RNN (LSTM or GRU)

The Update mechanism and the Policies are based on the codes:
https://github.com/Lizhi-sjtu/DRL-code-pytorch
https://github.com/DLR-RM/stable-baselines3

The environment is Custom desinged to resemble in-vitro cell environment in primitive format.

An additional GRU layer was applied as an Encoder in order to enphasise Delayed Gratification.

Number of parallel Agents can be arbitrarly scaled with the limit of resources. Furthermore a --collective_switch parameter is responsible for sharing memory across Agents.

Best results are generated by Discrete RNN GRU setting, high convergence in generic custom 2D matrix based environments over 1000 episodes.

Some of the functionalities are not available yet, but it is on it's way.
